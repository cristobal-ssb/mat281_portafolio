{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Tarea N°02\n",
    "## Instrucciones\n",
    "1.- Completa tus datos personales (nombre y rol USM) en siguiente celda.\n",
    "\n",
    "**Nombre**: Cristobal Salazar\n",
    "\n",
    "**Rol**: 201669515-k\n",
    "\n",
    "2.- Debes pushear este archivo con tus cambios a tu repositorio personal del curso, incluyendo datos, imágenes, scripts, etc.\n",
    "\n",
    "3.- Se evaluará:\n",
    "\n",
    "- Soluciones\n",
    "- Código\n",
    "- Que Binder esté bien configurado.\n",
    "- Al presionar  `Kernel -> Restart Kernel and Run All Cells` deben ejecutarse todas las celdas sin error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.- Clasificación de dígitos\n",
    "\n",
    "\n",
    "En este laboratorio realizaremos el trabajo de reconocer un dígito a partir de una imagen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rgb](https://www.wolfram.com/language/11/neural-networks/assets.en/digit-classification/smallthumb_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo es a partir de los datos, hacer la mejor predicción de cada imagen. Para ellos es necesario realizar los pasos clásicos de un proyecto de _Machine Learning_, como estadística descriptiva, visualización y preprocesamiento. \n",
    "\n",
    "* Se solicita ajustar al menos tres modelos de clasificación:\n",
    " * Regresión logística\n",
    " * K-Nearest Neighbours \n",
    " * Uno o más algoritmos a su elección [link](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning) (es obligación escoger un _estimator_ que tenga por lo menos un hiperparámetro). \n",
    " \n",
    " \n",
    "* En los modelos que posean hiperparámetros es mandatorio buscar el/los mejores con alguna técnica disponible en `scikit-learn` ([ver más](https://scikit-learn.org/stable/modules/grid_search.html#tuning-the-hyper-parameters-of-an-estimator)).\n",
    "* Para cada modelo, se debe realizar _Cross Validation_ con 10 _folds_ utilizando los datos de entrenamiento con tal de determinar un intervalo de confianza para el _score_ del modelo.\n",
    "* Realizar una predicción con cada uno de los tres modelos con los datos _test_ y obtener el _score_. \n",
    "* Analizar sus métricas de error (**accuracy**, **precision**, **recall**, **f-score**)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploración de los datos\n",
    "A continuación se carga el conjunto de datos a utilizar, a través del sub-módulo `datasets` de `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_dict = datasets.load_digits()\n",
    "print(digits_dict[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_dict[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se crea dataframe declarado como `digits` con los datos de `digits_dict` tal que tenga 65 columnas, las 6 primeras a la representación de la imagen en escala de grises (0-blanco, 255-negro) y la última correspondiente al dígito (`target`) con el nombre _target_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = (\n",
    "    pd.DataFrame(\n",
    "        digits_dict[\"data\"],\n",
    "    )\n",
    "    .rename(columns=lambda x: f\"c{x:02d}\")\n",
    "    .assign(target=digits_dict[\"target\"])\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "digits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1\n",
    "**Análisis exploratorio:** Realiza tu análisis exploratorio, no debes olvidar nada! Recuerda, cada análisis debe responder una pregunta.\n",
    "\n",
    "Algunas sugerencias:\n",
    "\n",
    "* ¿Cómo se distribuyen los datos?\n",
    "* ¿Cuánta memoria estoy utilizando?\n",
    "* ¿Qué tipo de datos son?\n",
    "* ¿Cuántos registros por clase hay?\n",
    "* ¿Hay registros que no se correspondan con tu conocimiento previo de los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Los datos de distribuyen en arreglos de 64 casillas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Memoria ocupada\n",
    "print(\"Los datos son del tipo:\",type(digits_dict['data'][0,0]))\n",
    "print('El numero de bits que ocupa un float es de 64')\n",
    "print(\"La cantidad de datos es:\", digits_dict['data'].size)\n",
    "print(\"\\nLa cantidad de memoria ocupada es de:\",digits_dict['data'].size*64,\"bits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Registros por clase\n",
    "for i in digits['target'].unique():\n",
    "    mask= (digits['target']==i)\n",
    "    k=len(digits[mask]['target'])\n",
    "    print(\"La cantidad de registros de la clase\",i,\"es de\",k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "**Visualización:** Para visualizar los datos utilizaremos el método `imshow` de `matplotlib`. Resulta necesario convertir el arreglo desde las dimensiones (1,64)  a (8,8) para que la imagen sea cuadrada y pueda distinguirse el dígito. Superpondremos además el label correspondiente al dígito, mediante el método `text`. Esto nos permitirá comparar la imagen generada con la etiqueta asociada a los valores. Realizaremos lo anterior para los primeros 25 datos del archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_dict[\"images\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualiza imágenes de los dígitos utilizando la llave `images` de `digits_dict`. \n",
    "\n",
    "Sugerencia: Utiliza `plt.subplots` y el método `imshow`. Puedes hacer una grilla de varias imágenes al mismo tiempo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx, ny = 5, 5\n",
    "fig, axs = plt.subplots(nx, ny, figsize=(12, 12))\n",
    "n=0\n",
    "for i in range(1,26):\n",
    "    etiqueta=['0','1','2','3','4','5','6','7','8','9']\n",
    "    img=digits_dict[\"images\"][i-1]\n",
    "    fig.add_subplot(nx,ny,i)\n",
    "    plt.imshow(img)\n",
    "    plt.text(4,4,etiqueta[n],fontsize=50,color='r')\n",
    "    n+=1\n",
    "    if n==(len(etiqueta)):\n",
    "        n=0\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3\n",
    "\n",
    "**Machine Learning**: En esta parte usted debe entrenar los distintos modelos escogidos desde la librería de `skelearn`. Para cada modelo, debe realizar los siguientes pasos:\n",
    "\n",
    "* **train-test** \n",
    " * Crear conjunto de entrenamiento y testeo (usted determine las proporciones adecuadas).\n",
    " * Imprimir por pantalla el largo del conjunto de entrenamiento y de testeo.\n",
    " \n",
    " \n",
    "* **modelo**:\n",
    " * Instanciar el modelo objetivo desde la librería sklearn.\n",
    " * *Hiper-parámetros*: Utiliza `sklearn.model_selection.GridSearchCV` para obtener la mejor estimación de los parámetros del modelo objetivo.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* **Métricas**:\n",
    " * Graficar matriz de confusión.\n",
    " * Analizar métricas de error.\n",
    "\n",
    "\n",
    "\n",
    "__Preguntas a responder:__\n",
    "\n",
    "* ¿Cuál modelo es mejor basado en sus métricas?\n",
    "* ¿Cuál modelo demora menos tiempo en ajustarse?\n",
    "* ¿Qué modelo escoges?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from metrics_classification import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.drop(columns=\"target\").values\n",
    "Y = digits[\"target\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Por simplicidad se usara la misma proporcion de datos para los 3 modelos que se utilizaran\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Separando informacion:\\n')\n",
    "print('numero de filas data original : ',len(X))\n",
    "print('numero de filas train set     : ',len(X_train))\n",
    "print('numero de filas test set      : ',len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlog = LogisticRegression()\n",
    "NB = KNeighborsClassifier()\n",
    "DTR = DecisionTreeRegressor()\n",
    "from sklearn.svm import SVC\n",
    "svc=SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti=time()\n",
    "rlog.fit(X_train, Y_train)\n",
    "tf=time()\n",
    "tp=tf-ti\n",
    "print(\"el tiempo de ejecucion de rlog es de\", tp, \"segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti=time()\n",
    "NB.fit(X_train, Y_train)\n",
    "tf=time()\n",
    "tp=tf-ti\n",
    "print(\"el tiempo de ejecucion de NB es de\", tp, \"segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti=time()\n",
    "svc.fit(X_train, Y_train)\n",
    "tf=time()\n",
    "tp=tf-ti\n",
    "print(\"el tiempo de ejecucion de DTR es de\", tp, \"segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true =  list(Y_test)\n",
    "y_pred = list(rlog.predict(X_test))\n",
    "\n",
    "print('\\nMatriz de confusion:\\n ')\n",
    "print(confusion_matrix(y_true,y_pred)) \n",
    "df_temp = pd.DataFrame(\n",
    "    {\n",
    "        'y':y_true,\n",
    "        'yhat':y_pred\n",
    "        }\n",
    ")\n",
    "\n",
    "df_metrics = summary_metrics(df_temp)\n",
    "print(\"\\nMetricas para los regresores : 'sepal length (cm)' y  'sepal width (cm)'\")\n",
    "print(\"\")\n",
    "print(df_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true =  list(Y_test)\n",
    "y_pred = list(NB.predict(X_test))\n",
    "\n",
    "print('\\nMatriz de confusion:\\n ')\n",
    "print(confusion_matrix(y_true,y_pred)) \n",
    "df_temp = pd.DataFrame(\n",
    "    {\n",
    "        'y':y_true,\n",
    "        'yhat':y_pred\n",
    "        }\n",
    ")\n",
    "\n",
    "df_metrics = summary_metrics(df_temp)\n",
    "print(\"\\nMetricas para los regresores : 'sepal length (cm)' y  'sepal width (cm)'\")\n",
    "print(\"\")\n",
    "print(df_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true =  list(Y_test)\n",
    "y_pred = list(svc.predict(X_test))\n",
    "\n",
    "print('\\nMatriz de confusion:\\n ')\n",
    "print(confusion_matrix(y_true,y_pred)) \n",
    "df_temp = pd.DataFrame(\n",
    "    {\n",
    "        'y':y_true,\n",
    "        'yhat':y_pred\n",
    "        }\n",
    ")\n",
    "\n",
    "df_metrics = summary_metrics(df_temp)\n",
    "print(\"\\nMetricas para los regresores : 'sepal length (cm)' y  'sepal width (cm)'\")\n",
    "print(\"\")\n",
    "print(df_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observar que el modelo NB es mejor ya que en las 4 metricas tiene valores mas cercanos a 1, lo que representa una mayor \n",
    "# precicion. Ademas el modelo NB tiene menor tiempo de ejecucion que los otros 2. Entonces por ambos motivos se escoge el modelo\n",
    "# NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 4\n",
    "\n",
    "__Comprensión del modelo:__ Tomando en cuenta el mejor modelo entontrado en el `Ejercicio 3`, debe comprender e interpretar minuciosamente los resultados y gráficos asocados al modelo en estudio, para ello debe resolver los siguientes puntos:\n",
    "\n",
    "\n",
    "\n",
    " * **Cross validation**: usando **cv** (con n_fold = 10), sacar una especie de \"intervalo de confianza\" sobre alguna de las métricas estudiadas en clases: \n",
    "  * $\\mu \\pm \\sigma$ = promedio $\\pm$ desviación estandar\n",
    " * **Curva de Validación**: Replica el ejemplo del siguiente [link](https://scikit-learn.org/stable/auto_examples/model_selection/plot_validation_curve.html#sphx-glr-auto-examples-model-selection-plot-validation-curve-py) pero con el modelo, parámetros y métrica adecuada. Saque conclusiones del gráfico.\n",
    " * **Curva AUC–ROC**: Replica el ejemplo del siguiente  [link](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py) pero con el modelo, parámetros y métrica adecuada. Saque conclusiones del gráfico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate,StratifiedKFold\n",
    "\n",
    "# creando pliegues\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10,\n",
    "                      random_state=2016)\n",
    "precision = []\n",
    "model =  KNeighborsClassifier()\n",
    "\n",
    "skf.get_n_splits(X_train, Y_train)\n",
    "for k, (train_index, test_index) in enumerate(skf.split(X, Y)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "    model.fit(X_train,Y_train) \n",
    "    score = model.score(X_test,Y_test)\n",
    "    precision.append(score)\n",
    "    print('Pliegue: {0:}, Dist Clase: {1:}, Prec: {2:.3f}'.format(k+1,\n",
    "                        np.bincount(Y_train), score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model =  KNeighborsClassifier()\n",
    "\n",
    "precision = cross_val_score(estimator=model,\n",
    "                            X=X_train,\n",
    "                            y=Y_train,\n",
    "                            cv=10)\n",
    "precision = [round(x,2) for x in precision]\n",
    "print('Precisiones: {} '.format(precision))\n",
    "print('Intervalo de confianza: {0: .3f} +/- {1: .3f}'.format(np.mean(precision),\n",
    "                                          np.std(precision)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "X, y = load_digits(return_X_y=True)\n",
    "\n",
    "param_range = np.logspace(-6, -1, 5)\n",
    "train_scores, test_scores = validation_curve(\n",
    "    KNeighborsClassifier(), X, y, param_name='n_neighbors', param_range=param_range,\n",
    "     scoring=\"f1_weighted\", n_jobs=4)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with SVM\")\n",
    "plt.xlabel(r\"$n_neighbors$\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Binarize the output\n",
    "y = label_binarize(y, classes=[0, 1, 2])\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "# Add noisy features to make the problem harder\n",
    "random_state = np.random.RandomState(0)\n",
    "n_samples, n_features = X.shape\n",
    "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Learn to predict each class against the other\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n",
    "                                 random_state=random_state))\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 5\n",
    "__Reducción de la dimensión:__ Tomando en cuenta el mejor modelo encontrado en el `Ejercicio 3`, debe realizar una redcción de dimensionalidad del conjunto de datos. Para ello debe abordar el problema ocupando los dos criterios visto en clases:  \n",
    "\n",
    "* **Selección de atributos**\n",
    "* **Extracción de atributos**\n",
    "\n",
    "__Preguntas a responder:__\n",
    "\n",
    "Una vez realizado la reducción de dimensionalidad, debe sacar algunas estadísticas y gráficas comparativas entre el conjunto de datos original y el nuevo conjunto de datos (tamaño del dataset, tiempo de ejecución del modelo, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FIX ME PLEASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 6\n",
    "\n",
    "\n",
    "__Visualizando Resultados:__ A continuación se provee código para comparar las etiquetas predichas vs las etiquetas reales del conjunto de _test_. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostar_resultados(digits,model,nx=5, ny=5,label = \"correctos\"):\n",
    "    \"\"\"\n",
    "    Muestra los resultados de las prediciones de un modelo \n",
    "    de clasificacion en particular. Se toman aleatoriamente los valores\n",
    "    de los resultados.\n",
    "    \n",
    "    - label == 'correcto': retorna los valores en que el modelo acierta.\n",
    "    - label == 'incorrecto': retorna los valores en que el modelo no acierta.\n",
    "\n",
    "    \n",
    "    Observacion: El modelo que recibe como argumento debe NO encontrarse\n",
    "    'entrenado'.\n",
    "    \n",
    "    \n",
    "    :param digits: dataset 'digits'\n",
    "    :param model: modelo de sklearn\n",
    "    :param nx: numero de filas (subplots)\n",
    "    :param ny: numero de columnas (subplots)\n",
    "    :param label: datos correctos o incorrectos\n",
    "    :return: graficos matplotlib\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    X = digits.drop(columns=\"target\").values\n",
    "    y = digits[\"target\"].values\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 42) \n",
    "    model.fit(X_train, Y_train) # ajustando el modelo\n",
    "    y_pred = list(model.predict(X_test))\n",
    "\n",
    "    \n",
    "    # Mostrar los datos correctos\n",
    "    if label==\"correctos\":\n",
    "        mask = (y_pred == y_test)\n",
    "        color = \"green\"\n",
    "        \n",
    "    # Mostrar los datos correctos\n",
    "    elif label==\"incorrectos\":\n",
    "        mask = (y_pred != y_test)\n",
    "        color = \"red\"\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Valor incorrecto\")\n",
    "        \n",
    "    X_aux = X_test\n",
    "    y_aux_true = y_test\n",
    "    y_aux_pred = y_pred\n",
    "\n",
    "    # We'll plot the first 100 examples, randomly choosen\n",
    "    fig, ax = plt.subplots(nx, ny, figsize=(12,12))\n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            index = j + ny * i\n",
    "            data  = X_aux[index, :].reshape(8,8)\n",
    "            label_pred = str(int(y_aux_pred[index]))\n",
    "            label_true = str(int(y_aux_true[index]))\n",
    "            ax[i][j].imshow(data, interpolation='nearest', cmap='gray_r')\n",
    "            ax[i][j].text(0, 0, label_pred, horizontalalignment='center', verticalalignment='center', fontsize=10, color=color)\n",
    "            ax[i][j].text(7, 0, label_true, horizontalalignment='center', verticalalignment='center', fontsize=10, color='blue')\n",
    "            ax[i][j].get_xaxis().set_visible(False)\n",
    "            ax[i][j].get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB=KNeighborsClassifier()\n",
    "mostar_resultados(digits,NB,nx=5, ny=5,label = \"correctos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta**\n",
    "\n",
    "* Tomando en cuenta el mejor modelo entontrado en el `Ejercicio 3`, grafique los resultados cuando:\n",
    " * el valor predicho y original son iguales\n",
    " * el valor predicho y original son distintos \n",
    "\n",
    "\n",
    "* Cuando el valor predicho y original son distintos ,  ¿Por qué ocurren estas fallas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FIX ME PLEASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 7\n",
    "**Conclusiones**: Entrega tu veredicto, responde las preguntas iniciales, visualizaciones, trabajos futuros, dificultades, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
